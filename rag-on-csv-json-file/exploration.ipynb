{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores import WeaviateDocumentStore\n",
    "from haystack import Pipeline\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "from haystack.nodes import EmbeddingRetriever, TextConverter, PreProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (if any)\n",
    "load_dotenv(\"../.env\")\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "weaviate_key = os.getenv(\"WEAVIATE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macpro/anaconda3/envs/llm-pipelines/lib/python3.10/multiprocessing/pool.py:265: ResourceWarning: unclosed running multiprocessing pool <multiprocessing.pool.ThreadPool state=RUN pool_size=8>\n",
      "  _warn(f\"unclosed running multiprocessing pool {self!r}\",\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/macpro/anaconda3/envs/llm-pipelines/lib/python3.10/site-packages/kaggle/api_client.py:181: DeprecationWarning: HTTPResponse.getheaders() is deprecated and will be removed in urllib3 v2.1.0. Instead access HTTPResponse.headers directly.\n",
      "  response_data.getheaders())\n",
      "/var/folders/2t/nqb9hcfs07n91h4v5p34slp00000gn/T/ipykernel_20036/432339802.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(str)\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files('papercool/organics-purchase-indicator', path='./', unzip=True)\n",
    "\n",
    "df = pd.read_csv('organics.csv')\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "# for all values under all columns, transform all values to string\n",
    "df = df.applymap(str)\n",
    "\n",
    "df.to_json('organics.json', orient='records', lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'customer_loyalty_id': '140',\n",
       " 'gender': 'U',\n",
       " 'geographic_region': 'Midlands',\n",
       " 'loyalty_status': 'Gold',\n",
       " 'neigborhood_cluster-55_level': '16.0',\n",
       " 'neighborhood_cluster-7_level': 'C',\n",
       " 'television_region': 'Wales & West',\n",
       " 'affluence_grade': '10',\n",
       " 'age': '76',\n",
       " 'frequency': '1',\n",
       " 'frequency_percent': '0.00%',\n",
       " 'loyalty_card_tenure': '4',\n",
       " 'organics_purchase_count': '0',\n",
       " 'organics_purchase_indicator': '0',\n",
       " 'total_spend': '16000.0'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('organics.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract and Transform Data\n",
    "transformed_documents = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "\n",
    "    transformed_documents.append( {\"content\":data[i]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for Document\ncontent\n  str type expected (type=type_error.str)\ncontent\n  instance of DataFrame expected (type=type_error.arbitrary_type; expected_arbitrary_type=DataFrame)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/macpro/Documents/GitHub/llmops-with-haystack/rag-on-csv-json-file/exploration.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macpro/Documents/GitHub/llmops-with-haystack/rag-on-csv-json-file/exploration.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m document_store \u001b[39m=\u001b[39m FAISSDocumentStore(faiss_index_factory_str\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFlat\u001b[39m\u001b[39m\"\u001b[39m, return_embedding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/macpro/Documents/GitHub/llmops-with-haystack/rag-on-csv-json-file/exploration.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Step 2: Write Transformed Data to Document Store\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/macpro/Documents/GitHub/llmops-with-haystack/rag-on-csv-json-file/exploration.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m document_store\u001b[39m.\u001b[39;49mwrite_documents(transformed_documents)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-pipelines/lib/python3.10/site-packages/haystack/document_stores/faiss.py:256\u001b[0m, in \u001b[0;36mFAISSDocumentStore.write_documents\u001b[0;34m(self, documents, index, batch_size, duplicate_documents, headers)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfaiss_indexes[index] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_new_index(\n\u001b[1;32m    250\u001b[0m         embedding_dim\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_dim,\n\u001b[1;32m    251\u001b[0m         index_factory\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfaiss_index_factory_str,\n\u001b[1;32m    252\u001b[0m         metric_type\u001b[39m=\u001b[39mfaiss\u001b[39m.\u001b[39mMETRIC_INNER_PRODUCT,\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    255\u001b[0m field_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_document_field_map()\n\u001b[0;32m--> 256\u001b[0m document_objects \u001b[39m=\u001b[39m [Document\u001b[39m.\u001b[39mfrom_dict(d, field_map\u001b[39m=\u001b[39mfield_map) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m d \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    257\u001b[0m document_objects \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_duplicate_documents(\n\u001b[1;32m    258\u001b[0m     documents\u001b[39m=\u001b[39mdocument_objects, index\u001b[39m=\u001b[39mindex, duplicate_documents\u001b[39m=\u001b[39mduplicate_documents\n\u001b[1;32m    259\u001b[0m )\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(document_objects) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-pipelines/lib/python3.10/site-packages/haystack/document_stores/faiss.py:256\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfaiss_indexes[index] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_new_index(\n\u001b[1;32m    250\u001b[0m         embedding_dim\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_dim,\n\u001b[1;32m    251\u001b[0m         index_factory\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfaiss_index_factory_str,\n\u001b[1;32m    252\u001b[0m         metric_type\u001b[39m=\u001b[39mfaiss\u001b[39m.\u001b[39mMETRIC_INNER_PRODUCT,\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    255\u001b[0m field_map \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_document_field_map()\n\u001b[0;32m--> 256\u001b[0m document_objects \u001b[39m=\u001b[39m [Document\u001b[39m.\u001b[39;49mfrom_dict(d, field_map\u001b[39m=\u001b[39;49mfield_map) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(d, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m d \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    257\u001b[0m document_objects \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_duplicate_documents(\n\u001b[1;32m    258\u001b[0m     documents\u001b[39m=\u001b[39mdocument_objects, index\u001b[39m=\u001b[39mindex, duplicate_documents\u001b[39m=\u001b[39mduplicate_documents\n\u001b[1;32m    259\u001b[0m )\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(document_objects) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-pipelines/lib/python3.10/site-packages/haystack/schema.py:236\u001b[0m, in \u001b[0;36mDocument.from_dict\u001b[0;34m(cls, dict, field_map)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m _new_doc\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontent_type\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(_new_doc[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[1;32m    234\u001b[0m     _new_doc[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataframe_from_list(_new_doc[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 236\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_new_doc)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-pipelines/lib/python3.10/site-packages/pydantic/dataclasses.py:325\u001b[0m, in \u001b[0;36mpydantic.dataclasses._add_pydantic_validation_attributes.new_init\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-pipelines/lib/python3.10/site-packages/pydantic/dataclasses.py:425\u001b[0m, in \u001b[0;36mpydantic.dataclasses._dataclass_validate_values\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for Document\ncontent\n  str type expected (type=type_error.str)\ncontent\n  instance of DataFrame expected (type=type_error.arbitrary_type; expected_arbitrary_type=DataFrame)"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores import FAISSDocumentStore\n",
    "\n",
    "\n",
    "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\", return_embedding=True)\n",
    "\n",
    "# Step 2: Write Transformed Data to Document Store\n",
    "document_store.write_documents(transformed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': []}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "auth_config = weaviate.AuthApiKey(api_key=weaviate_key)\n",
    "\n",
    "client = weaviate.Client(\n",
    "  url=\"https://kaggle-dataset-jxnlf95q.weaviate.network\",\n",
    "  auth_client_secret=auth_config\n",
    ")\n",
    "\n",
    "client.schema.get()  # Get the schema to test connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_obj = {\n",
    "    \"class\": \"Organics3\",\n",
    "    \"description\": \"Information from a customer's organic purchases\",  # description of the class\n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Unique identifier for customer loyalty\",\n",
    "            \"name\": \"customer_loyalty_id\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Gender of the customer\",\n",
    "            \"name\": \"gender\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Geographic region of the customer\",\n",
    "            \"name\": \"geographic_region\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Loyalty status of the customer\",\n",
    "            \"name\": \"loyalty_status\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Neighborhood cluster at 55 level\",\n",
    "            \"name\": \"neigborhood_cluster_55_level\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Neighborhood cluster at 7 level\",\n",
    "            \"name\": \"neighborhood_cluster_7_level\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Television region of the customer\",\n",
    "            \"name\": \"television_region\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Affluence grade of the customer\",\n",
    "            \"name\": \"affluence_grade\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Age of the customer\",\n",
    "            \"name\": \"age\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Frequency of purchases\",\n",
    "            \"name\": \"frequency\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Frequency percent of purchases\",\n",
    "            \"name\": \"frequency_percent\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Tenure of loyalty card\",\n",
    "            \"name\": \"loyalty_card_tenure\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Count of organic purchases\",\n",
    "            \"name\": \"organics_purchase_count\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Indicator of organic purchases\",\n",
    "            \"name\": \"organics_purchase_indicator\",\n",
    "        },\n",
    "        {\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Total spend by the customer\",\n",
    "            \"name\": \"total_spend\",\n",
    "        },\n",
    "    ],\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "}\n",
    "\n",
    "\n",
    "# add the schema\n",
    "client.schema.create_class(class_obj)\n",
    "\n",
    "# get the schema\n",
    "schema = client.schema.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.schema.get() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = WeaviateDocumentStore(host='https://kaggle-dataset-jxnlf95q.weaviate.network',\n",
    "                                       embedding_dim=768,\n",
    "                                       port=8080,\n",
    "                                       api_key=weaviate_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = TextConverter(remove_numeric_tables=False, valid_languages=[\"en\"])\n",
    "doc_txt = converter.convert(file_path=\"organics.txt\", meta=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessor = PreProcessor()\n",
    "retriever = EmbeddingRetriever(document_store = document_store,\n",
    "                               embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_node(component=converter, name=\"TextConverter\", inputs=[\"File\"])\n",
    "indexing_pipeline.add_node(component=preprocessor, name=\"PreProcessor\", inputs=[\"PDFConverter\"])\n",
    "indexing_pipeline.add_node(component=retriever, name=\"Retriever\", inputs=[\"PreProcessor\"])\n",
    "indexing_pipeline.add_node(component=document_store, name=\"DocumentStore\", inputs=[\"Retriever\"])\n",
    "\n",
    "indexing_pipeline.run(file_paths=[\"filename.pdf\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-pipelines",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
